{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10f94e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# PHASE 3: TIME SERIES MODELING & CAUSALITY (FULL ADJUSTMENT)\n",
    "# =========================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller, grangercausalitytests\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from causalimpact import CausalImpact\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Define File Path ---\n",
    "# Assuming the final imputed CSV from the previous step is the input\n",
    "FINAL_IMPUTED_FILE = '../data/merged_timeseries_final_imputed.csv' \n",
    "\n",
    "# Load the merged and imputed data\n",
    "# NOTE: If your imputation step saved the file as 'merged_timeseries.csv' \n",
    "# in the data folder, update the file name here.\n",
    "df = pd.read_csv(FINAL_IMPUTED_FILE, index_col='date', parse_dates=True).dropna()\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.index = df.index.tz_localize(None) \n",
    "df.index.name = 'date'\n",
    "\n",
    "# --- Define Variables for Modeling ---\n",
    "DEPENDENT_VAR = 'nft_sales_volume_eth'\n",
    "PRIMARY_EXOG = ['avg_gas_price_gwei'] # The cause variable (X)\n",
    "\n",
    "# All Confounders (C): ETH Price, Sentiment Score, New Addresses\n",
    "CONFOUNDERS = ['eth_price_usd', 'fear_greed_score', 'new_addresses']\n",
    "ALL_EXOG_VARS = PRIMARY_EXOG + CONFOUNDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8d1a9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ADF Test for Stationarity (Determining Integration Order 'd') ---\n",
      "NFT Volume p-value: 0.0000\n",
      "Gas Price p-value: 0.0000\n",
      "\n",
      "--- Granger Causality Test: Gas Price -> NFT Volume (MANUALLY Adjusted) ---\n",
      "Adjusted Granger Test Results (Lag 7):\n",
      "F-statistic: 1.6887\n",
      "P-value (Adjusted): 0.1167\n",
      "\n",
      "CONCLUSION: P >= 0.05. We fail to reject H0. No Adjusted Granger Causality detected.\n"
     ]
    }
   ],
   "source": [
    "# --- Corrected Chunk 2: Stationarity and Controlled Granger Causality ---\n",
    "\n",
    "# Import for the final statistical test (scipy is usually standard)\n",
    "from scipy.stats import f # Used for the F-Test calculation\n",
    "\n",
    "# --- (a) Stationarity Check (ADF Test) ---\n",
    "print(\"--- ADF Test for Stationarity (Determining Integration Order 'd') ---\")\n",
    "\n",
    "def check_stationarity(series, name):\n",
    "    # Use 1st difference (series.diff().dropna())\n",
    "    result = adfuller(series.diff().dropna()) \n",
    "    print(f'{name} p-value: {result[1]:.4f}')\n",
    "    \n",
    "check_stationarity(df[DEPENDENT_VAR], 'NFT Volume')\n",
    "check_stationarity(df['avg_gas_price_gwei'], 'Gas Price')\n",
    "\n",
    "\n",
    "# --- (b) Controlled Granger Causality Test (Manual OLS F-Test using RSS) ---\n",
    "# Goal: Test if Gas Price (X) predicts NFT Volume (Y), controlling for Confounders (C).\n",
    "print(\"\\n--- Granger Causality Test: Gas Price -> NFT Volume (MANUALLY Adjusted) ---\")\n",
    "\n",
    "# 1. Prepare Data\n",
    "# The analysis requires all variables to be stationary. Use the 1st difference (d=1).\n",
    "data_diff = df[[DEPENDENT_VAR] + PRIMARY_EXOG + CONFOUNDERS].diff().dropna()\n",
    "LAG = 7 # We test for causality at 7 days\n",
    "\n",
    "y_var = data_diff[DEPENDENT_VAR]\n",
    "X_vars = data_diff[PRIMARY_EXOG + CONFOUNDERS]\n",
    "\n",
    "# 2. Build the Restricted Model (H0: X does NOT cause Y)\n",
    "restricted_X = []\n",
    "for i in range(1, LAG + 1):\n",
    "    restricted_X.append(y_var.shift(i).fillna(0)) # Lagged Y\n",
    "    for col in CONFOUNDERS:\n",
    "        restricted_X.append(X_vars[col].shift(i).fillna(0)) # Lagged Confounders (C)\n",
    "\n",
    "restricted_X = pd.concat(restricted_X, axis=1).iloc[LAG:]\n",
    "restricted_X = sm.add_constant(restricted_X, prepend=False)\n",
    "restricted_y = y_var[LAG:]\n",
    "\n",
    "# Fit the Restricted Model\n",
    "restricted_model = sm.OLS(restricted_y, restricted_X).fit()\n",
    "\n",
    "\n",
    "# 3. Build the Unrestricted Model (H1: X DOES cause Y)\n",
    "unrestricted_X = []\n",
    "for i in range(1, LAG + 1):\n",
    "    unrestricted_X.append(y_var.shift(i).fillna(0)) # Lagged Y\n",
    "    for col in CONFOUNDERS:\n",
    "        unrestricted_X.append(X_vars[col].shift(i).fillna(0)) # Lagged C\n",
    "    for col in PRIMARY_EXOG:\n",
    "         unrestricted_X.append(X_vars[col].shift(i).fillna(0)) # Lagged X (Gas Price)\n",
    "\n",
    "unrestricted_X = pd.concat(unrestricted_X, axis=1).iloc[LAG:]\n",
    "unrestricted_X = sm.add_constant(unrestricted_X, prepend=False)\n",
    "\n",
    "# Fit the Unrestricted Model\n",
    "unrestricted_model = sm.OLS(restricted_y, unrestricted_X).fit()\n",
    "\n",
    "\n",
    "# 4. Perform the F-Test Manually using Residual Sum of Squares (RSS)\n",
    "RSS_R = restricted_model.ssr # RSS of the Restricted Model\n",
    "RSS_U = unrestricted_model.ssr # RSS of the Unrestricted Model\n",
    "\n",
    "q = len(PRIMARY_EXOG) * LAG # Number of restrictions (lags * variables tested)\n",
    "T = len(restricted_y) # Number of observations\n",
    "k = unrestricted_model.df_model + 1 # Number of parameters in the unrestricted model\n",
    "\n",
    "# F-statistic formula: ((RSS_R - RSS_U) / q) / (RSS_U / (T - k))\n",
    "F_statistic = ((RSS_R - RSS_U) / q) / (RSS_U / (T - k))\n",
    "\n",
    "# Calculate the P-value from the F-distribution\n",
    "p_value_adjusted = f.sf(F_statistic, q, T - k) # f.sf is the survival function (1 - CDF)\n",
    "\n",
    "print(f\"Adjusted Granger Test Results (Lag {LAG}):\")\n",
    "print(f\"F-statistic: {F_statistic:.4f}\")\n",
    "print(f\"P-value (Adjusted): {p_value_adjusted:.4f}\")\n",
    "\n",
    "if p_value_adjusted < 0.05:\n",
    "    print(\"\\nCONCLUSION: P < 0.05. We reject H0. Gas Price **DOES** Granger-cause NFT Volume, even when controlling for Confounders.\")\n",
    "else:\n",
    "    print(\"\\nCONCLUSION: P >= 0.05. We fail to reject H0. No Adjusted Granger Causality detected.\")\n",
    "\n",
    "# --- End of Chunk 2 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6a94053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ARIMAX Model: NFT Volume (Y) explained by Gas Price (X) [Full Adjustment] ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Devi\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Devi\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                SARIMAX Results                                 \n",
      "================================================================================\n",
      "Dep. Variable:     nft_sales_volume_eth   No. Observations:                  180\n",
      "Model:                 SARIMAX(1, 1, 1)   Log Likelihood               -1627.866\n",
      "Date:                  Sun, 02 Nov 2025   AIC                           3269.731\n",
      "Time:                          22:37:04   BIC                           3291.964\n",
      "Sample:                      05-06-2025   HQIC                          3278.748\n",
      "                           - 11-01-2025                                         \n",
      "Covariance Type:                    opg                                         \n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "avg_gas_price_gwei    78.6995    159.048      0.495      0.621    -233.029     390.428\n",
      "eth_price_usd          0.2268      0.667      0.340      0.734      -1.080       1.534\n",
      "fear_greed_score      21.3312     36.143      0.590      0.555     -49.509      92.171\n",
      "new_addresses         -0.0018      0.017     -0.107      0.915      -0.036       0.032\n",
      "ar.L1                  0.0559      0.086      0.649      0.516      -0.113       0.225\n",
      "ma.L1                 -1.0636      0.037    -28.732      0.000      -1.136      -0.991\n",
      "sigma2              6.657e+06      0.027   2.44e+08      0.000    6.66e+06    6.66e+06\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.42   Jarque-Bera (JB):              1099.05\n",
      "Prob(Q):                              0.52   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.21   Skew:                             2.70\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        13.95\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "[2] Covariance matrix is singular or near-singular, with condition number 2.81e+23. Standard errors may be unstable.\n",
      "\n",
      "ADJUSTED Gas Price Coefficient (Isolated Effect): 78.6995\n",
      "Fear & Greed Score Coefficient (Confounder Control): 21.3312\n"
     ]
    }
   ],
   "source": [
    "# --- (c) ARIMAX Model Fitting (Full Adjustment) ---\n",
    "# Model isolates the coefficient of 'avg_gas_price_gwei' (Primary Exogenous)\n",
    "print(\"\\n--- ARIMAX Model: NFT Volume (Y) explained by Gas Price (X) [Full Adjustment] ---\")\n",
    "\n",
    "endog = df[DEPENDENT_VAR]\n",
    "exog = df[ALL_EXOG_VARS] # Includes Gas Price AND Confounders\n",
    "\n",
    "# Fit the SARIMAX model: (p, d, q) = (1, 1, 1) is a common starting point\n",
    "# d=1 is used because we anticipate non-stationarity (as confirmed by ADF likely).\n",
    "model = SARIMAX(endog, exog=exog, order=(1,1,1), enforce_stationarity=False, enforce_invertibility=False)\n",
    "results = model.fit(disp=False)\n",
    "print(results.summary())\n",
    "\n",
    "# Key Interpretation: Look at the coefficient for the primary variable\n",
    "print(f\"\\nADJUSTED Gas Price Coefficient (Isolated Effect): {results.params['avg_gas_price_gwei']:.4f}\")\n",
    "print(f\"Fear & Greed Score Coefficient (Confounder Control): {results.params['fear_greed_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30c1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ARIMAX Model: NFT Volume (Y) explained by Gas Price (X) [SIMPLIFIED ADJUSTMENT] ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Devi\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Devi\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                SARIMAX Results                                 \n",
      "================================================================================\n",
      "Dep. Variable:     nft_sales_volume_eth   No. Observations:                  180\n",
      "Model:                 SARIMAX(1, 1, 1)   Log Likelihood               -1627.387\n",
      "Date:                  Sun, 02 Nov 2025   AIC                           3266.774\n",
      "Time:                          19:54:52   BIC                           3285.831\n",
      "Sample:                      05-06-2025   HQIC                          3274.503\n",
      "                           - 11-01-2025                                         \n",
      "Covariance Type:                    opg                                         \n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "avg_gas_price_gwei    70.0572    193.297      0.362      0.717    -308.799     448.913\n",
      "eth_price_usd          0.0850      0.683      0.124      0.901      -1.254       1.424\n",
      "fear_greed_score      36.5834     36.727      0.996      0.319     -35.401     108.568\n",
      "ar.L1                  0.0551      0.084      0.653      0.514      -0.110       0.221\n",
      "ma.L1                 -1.0573      0.042    -24.895      0.000      -1.141      -0.974\n",
      "sigma2              6.558e+06   6.46e+05     10.150      0.000    5.29e+06    7.82e+06\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.43   Jarque-Bera (JB):              1101.66\n",
      "Prob(Q):                              0.51   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.20   Skew:                             2.67\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        13.99\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "\n",
      "ADJUSTED Gas Price Coefficient (Isolated Effect): 70.0572\n"
     ]
    }
   ],
   "source": [
    "# # --- Chunk 3: ARIMAX Model Fitting (SIMPLIFIED ADJUSTMENT) ---\n",
    "\n",
    "# print(\"\\n--- ARIMAX Model: NFT Volume (Y) explained by Gas Price (X) [SIMPLIFIED ADJUSTMENT] ---\")\n",
    "\n",
    "# # RE-DEFINE CONFOUNDERS FOR ARIMAX: We prioritize the essential controls (ETH Price and Sentiment)\n",
    "# ARIMAX_CONFOUNDERS = ['eth_price_usd', 'fear_greed_score']\n",
    "# ARIMAX_EXOG_VARS = PRIMARY_EXOG + ARIMAX_CONFOUNDERS\n",
    "\n",
    "# endog = df[DEPENDENT_VAR]\n",
    "# exog = df[ARIMAX_EXOG_VARS] \n",
    "\n",
    "# # Fit the SARIMAX model: order=(p, d, q) = (1, 1, 1)\n",
    "# model = SARIMAX(endog, exog=exog, order=(1,1,1), enforce_stationarity=False, enforce_invertibility=False)\n",
    "# results = model.fit(disp=False)\n",
    "\n",
    "# # Check for successful convergence before proceeding\n",
    "# if results is None:\n",
    "#     print(\"\\nFATAL ERROR: ARIMAX model failed to converge (returned None). Check data stability.\")\n",
    "#     # Set a placeholder variable to avoid crashing Chunk 4 later\n",
    "#     ARIMAX_RESULTS = None\n",
    "# else:\n",
    "#     print(results.summary())\n",
    "\n",
    "#     # Key Interpretation: Look at the coefficient for the primary variable (Gas Price)\n",
    "#     print(f\"\\nADJUSTED Gas Price Coefficient (Isolated Effect): {results.params['avg_gas_price_gwei']:.4f}\")\n",
    "    \n",
    "#     # Store the results object for safe use in Chunk 4\n",
    "#     ARIMAX_RESULTS = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71662cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- OLS Interrupted Time Series Analysis (Testing Multiple Events) ---\n",
      "\n",
      "========================================\n",
      "ANALYZING EVENT: Initial Spike (Aug)\n",
      "Level Shift Coef (Z_Intervention): 3865.67 ETH\n",
      "P-value for Shift: 0.0315\n",
      ">>> CONCLUSION: Significant Level Shift (Effect Confirmed).\n",
      "\n",
      "========================================\n",
      "ANALYZING EVENT: Mid-Autumn Volatility\n",
      "Level Shift Coef (Z_Intervention): 174.98 ETH\n",
      "P-value for Shift: 0.6336\n",
      ">>> CONCLUSION: No Significant Level Shift (Effect Absent).\n",
      "\n",
      "========================================\n",
      "ANALYZING EVENT: Late-Year Rush\n",
      "Level Shift Coef (Z_Intervention): -1429.85 ETH\n",
      "P-value for Shift: 0.0341\n",
      ">>> CONCLUSION: Significant Level Shift (Effect Confirmed).\n"
     ]
    }
   ],
   "source": [
    "# --- Chunk 4: Interrupted Time Series Analysis (Iterative OLS) ---\n",
    "print(\"\\n--- OLS Interrupted Time Series Analysis (Testing Multiple Events) ---\")\n",
    "\n",
    "# DEFINE MULTIPLE INTERVENTION PERIODS based on your data spikes\n",
    "# Use dates that show significant gas activity in the post_period.\n",
    "INTERVENTIONS = [\n",
    "    {\n",
    "        'name': 'Initial Spike (Aug)', \n",
    "        'pre': ['2025-05-05', '2025-07-20'], \n",
    "        'post': ['2025-07-21', '2025-08-21']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Mid-Autumn Volatility',\n",
    "        'pre': ['2025-08-10', '2025-09-10'],\n",
    "        'post': ['2025-09-11', '2025-10-11']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Late-Year Rush',\n",
    "        'pre': ['2025-09-20', '2025-10-25'],\n",
    "        'post': ['2025-10-26', '2025-11-20']\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define OLS Model Variables (Y and Controls C)\n",
    "y = df[DEPENDENT_VAR]\n",
    "CONTROL_VARS = ['avg_gas_price_gwei', 'eth_price_usd', 'fear_greed_score', 'new_addresses']\n",
    "X_vars_base = df[CONTROL_VARS].copy() # Base controls\n",
    "\n",
    "# --- Run Analysis for Each Intervention ---\n",
    "for intervention in INTERVENTIONS:\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"ANALYZING EVENT: {intervention['name']}\")\n",
    "    \n",
    "    # 1. Create the Intervention Dummy (Z) for this specific period\n",
    "    pre_start, pre_end = pd.to_datetime(intervention['pre'])\n",
    "    post_start, post_end = pd.to_datetime(intervention['post'])\n",
    "\n",
    "    # Ensure the combined data covers both periods\n",
    "    df_event = df.loc[pre_start:post_end].copy()\n",
    "    \n",
    "    # Z_Intervention = 1 during the post-period, 0 otherwise\n",
    "    df_event['Z_Intervention'] = np.where(df_event.index >= post_start, 1, 0)\n",
    "    \n",
    "    # 2. Define the Model Inputs\n",
    "    y_event = df_event[DEPENDENT_VAR]\n",
    "    X_event = df_event[['Z_Intervention'] + CONTROL_VARS]\n",
    "    X_event = sm.add_constant(X_event)\n",
    "\n",
    "    # 3. Fit the OLS Model\n",
    "    try:\n",
    "        ols_model = sm.OLS(y_event, X_event).fit()\n",
    "        \n",
    "        # 4. Print Key Results\n",
    "        intervention_coeff = ols_model.params['Z_Intervention']\n",
    "        p_value_ols = ols_model.pvalues['Z_Intervention']\n",
    "\n",
    "        print(f\"Level Shift Coef (Z_Intervention): {intervention_coeff:.2f} ETH\")\n",
    "        print(f\"P-value for Shift: {p_value_ols:.4f}\")\n",
    "\n",
    "        if p_value_ols < 0.05:\n",
    "            print(\">>> CONCLUSION: Significant Level Shift (Effect Confirmed).\")\n",
    "        else:\n",
    "            print(\">>> CONCLUSION: No Significant Level Shift (Effect Absent).\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Model failed to fit for {intervention['name']}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
